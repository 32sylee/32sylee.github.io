---
layout: post
title: "하둡 분산 파일 시스템(HDFS)"
author: "Sooyeon"
---
# 하둡 분산 파일 시스템(HDFS)이란?

- HDFS(HAdoop Distributed File System) - 수십 테라바이트 또는 페타바이트 이상의 대용량 파일을 분산된 서버에 저장하고, 많은 클라이언트가 저장된 데이터를 빠르게 처리할 수 있게 설계된 파일 시스템.

### HDFD의 설계 목표

- 장애 복구: 복제본도 함께 저장
- 스트리밍 방식의 데이터 접근: 랜덤 방식의 데이터 접근 X
- 대용량 데이터 저장
- 데이터 무결성: 한번 저장한 데이터는 수정 불가. 읽기만 가능.

# HDFS 아키텍처

## 블록 구조 파일 시스템

HDFS는 블록 구조의 파일 시스템. HDFS에 저장하는 파일은 특정 크기의 블록으로 나눠져 분산된 서버에 저장된다.

블록의 기본 사이즈 - 64MB (변경 가능)

블록 사이즈가 64MB인 이유
- dist seek time 감소
- 네임노드가 유지하는 메타데이터 크기 감소
- 클라이언트와 네임노드의 통신 감소

HDFS는 기본적으로 블록 복제본을 3개씩 저장.

64MB보다 작은 파일이더라도 무조건 64MB가 아닌 크기에 맞게 저장됨.

## 컴포넌트

HDFS는 master-slave 아키텍처.
-  마스터 - NameNode
- 슬레이브 - DataNode

### 네임노드

- 메타데이터 관리
- 데이터노드 모니터링
- 블록 관리
- 클라이언트 요청 접수

### 데이터노드

- 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지.
    - raw data(실제 데이터)
    - 메타데이터 설정 파일

### 보조네임노드
네임노드는 메타데이터를 메모리에서 처리. 하지만 메모리에만 데이터를 유지할 경우 서버가 재부팅되면 모든 메타데이터가 유실될 수 있다.

HDFS는 이를 극복하기 위해 두 개의 파일을 생성
- editslog: HDFS의 모든 변경 이력을 저장
- fsimage: 메모리에 저장된 메타데이터의 파일 시스템 이미지를 저장

editslog의 크기는 별도의 제한이 없어 무한대로 커질 수 있다. editslog의 크기가 너무 커지면 문제가 됨.

이를 해결하기 위한 것이 보조네임노드.

- 보조네임노드 - 주기적으로 네임노드의 fsimage를 갱신(체크포인트)